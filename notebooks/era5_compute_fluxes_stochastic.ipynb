{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8d10980",
   "metadata": {},
   "source": [
    "# Stochastic compute ERA5 fluxes\n",
    "Clone of the 2014 compute fluxes, however now using a stochastic implementation.\n",
    "\n",
    "Care needs to be taken in this case to isolate blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87012e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Master Variables\n",
    "dc = 0.4 # Spectral resolution\n",
    "exclude_unbroken = False # Exclude waves that are unbroken at top level from the momentum flux calculations? \n",
    "use_intrinsic_c = 'always' # always center distributon on zero intrinsic phase speed vs never (center on zero ground relative speed) or switch at latitude ? \n",
    "Fs0 = 4.3e-3 # Pa, initial momentum flux at source level\n",
    "cw = 35 # m/s, gravity wave phase speed source distribution half width at half maximum "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a56e590",
   "metadata": {},
   "source": [
    "## dask/SLURM setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b240b2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import SLURMCluster\n",
    "NCORES = 8\n",
    "NPROCESS = 8\n",
    "NCORESPERPROCESS = NCORES//NPROCESS\n",
    "constraints = ['-C \\\"CLASS:SH4_CBASE|CLASS:SH4_CPERF\\\"'] # SH4 nodes are the fastest, and mixing node gens seems to cause ib0 issues.\n",
    "cluster = SLURMCluster(queue='serc',memory='96GiB',cores=NCORES,processes=NPROCESS,walltime='06:00:00',job_extra_directives=constraints,log_directory='/scratch/users/robcking/dask_worker_logs')\n",
    "cluster.scale(jobs=25) # roughly but tune to scheduler \n",
    "cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4374e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client \n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ee3a1a",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe332d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import dask.array as da\n",
    "import cartopy.crs as ccrs \n",
    "## Load in from ERA5 GCP public dataset\n",
    "PATH_COARSE = 'gs://gcp-public-data-arco-era5/ar/1959-2022-1h-240x121_equiangular_with_poles_conservative.zarr'\n",
    "variables = ['u_component_of_wind','v_component_of_wind','temperature','geopotential']\n",
    "ds = xr.open_zarr(PATH_COARSE,chunks={})\n",
    "ds_4xdaily = ds.sel(time=slice('2014-01-01','2015-01-01',6))\n",
    "ds_4xdaily = ds_4xdaily.chunk({'time':1})\n",
    "ds_4xdaily_reduce = ds_4xdaily[variables]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad763e8",
   "metadata": {},
   "source": [
    "### coarsen ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d69c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xesmf as xe \n",
    "\n",
    "longitudes = np.linspace(0,360,128,endpoint=False)\n",
    "\n",
    "N = 64  # Number of latitude points\n",
    "x, w = np.polynomial.legendre.leggauss(N)  # x are roots (in [-1, 1]), w are weights\n",
    "latitudes_radians = np.arcsin(x)  # Convert from Gauss x-space to latitude in radians\n",
    "latitudes= np.degrees(latitudes_radians)\n",
    "\n",
    "ds_4xdaily_regrid = xr.Dataset({\n",
    "    'longitude':(['longitude'],longitudes,{\"units\": \"degrees_east\"}),\n",
    "    'latitude':(['latitude'],latitudes,{\"units\": \"degrees_north\"})\n",
    "})\n",
    "regridder = xe.Regridder(ds_4xdaily_reduce,ds_4xdaily_regrid,'bilinear',periodic=True)\n",
    "ds_4xdaily_regrid = regridder(ds_4xdaily_reduce).persist()\n",
    "\n",
    "ds_4xdaily_regrid = ds_4xdaily_regrid.isel(level=slice(None,None,-1))\n",
    "ds_4xdaily_regrid= ds_4xdaily_regrid.transpose(\"time\",\"longitude\",\"latitude\",\"level\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668a62d3",
   "metadata": {},
   "source": [
    "### setup AD99 input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8677e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ad99py import GRAV,C_P,BFLIM,R_DRY\n",
    "from ad99py.variables import bouyancy_freq_squared,density\n",
    "\n",
    "us = ds_4xdaily_regrid.u_component_of_wind.data\n",
    "vs = ds_4xdaily_regrid.v_component_of_wind.data\n",
    "temps = ds_4xdaily_regrid.temperature.data\n",
    "height = ds_4xdaily_regrid.geopotential.data / GRAV\n",
    "\n",
    "Ns = bouyancy_freq_squared(temps,height)**0.5\n",
    "rho = density(temps,ds_4xdaily_regrid.level.data)\n",
    "\n",
    "lat = da.broadcast_to(ds_4xdaily_regrid.latitude.data[None,None,:],us.shape[:-1]).astype(np.float32)\n",
    "lat = lat.rechunk((1,-1,-1,))\n",
    "lat_4d = lat[..., None]         # now shape = (11688, 240, 121, 1)\n",
    "lat_4d = lat_4d.rechunk((1,-1,-1,-1)).persist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1627ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import progress\n",
    "us,vs,height,Ns,rho = dask.persist(us,vs,height,Ns,rho)\n",
    "progress(Ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54640ee7",
   "metadata": {},
   "source": [
    "## Define blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5188d4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42 # for reproducibility\n",
    "master = np.random.SeedSequence(SEED)\n",
    "n_blocks = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42578d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ad99py.ad99stochastic import AlexanderDunkerton1999Stochastic\n",
    "\n",
    "def dask_ad99_map_block(ublock,vblock,Nblock,zblock,rhoblock,latblock,seed):\n",
    "    \"\"\"\n",
    "    Map indivudal blocks by linearly running them through the parameterization. \n",
    "    Not very fast or efficient right now but could be optimized further in future\n",
    "    \"\"\"\n",
    "    ## Use same seed for both u and v to ensure consistent sampling?\n",
    "    rng_u = np.random.default_rng(seed)\n",
    "    rng_v = np.random.default_rng(seed)\n",
    "    ad99_u = AlexanderDunkerton1999Stochastic(\n",
    "        rng=rng_u,\n",
    "        Fs0 = Fs0,\n",
    "        Fs0_sigma = 1, # NEW CONSTRAINED PARAMETER! \n",
    "        cw=cw,\n",
    "        exclude_unbroken=exclude_unbroken,\n",
    "        use_intrinsic_c=use_intrinsic_c,\n",
    "        Fs0_meaning='mean'\n",
    "    )\n",
    "    ad99_v = AlexanderDunkerton1999Stochastic(\n",
    "        rng=rng_v,\n",
    "        Fs0 = Fs0,\n",
    "        Fs0_sigma = 1, # NEW CONSTRAINED PARAMETER! \n",
    "        cw=cw,\n",
    "        exclude_unbroken=exclude_unbroken,\n",
    "        use_intrinsic_c=use_intrinsic_c,\n",
    "        Fs0_meaning='mean'\n",
    "    )\n",
    "    batch_shape = ublock.shape[:-1]\n",
    "    nlevels = ublock.shape[-1]\n",
    "    \n",
    "    ublock_flt = ublock.reshape((-1,nlevels))\n",
    "    vblock_flt = vblock.reshape((-1,nlevels))\n",
    "    Nblock_flt = Nblock.reshape((-1,nlevels))\n",
    "    zblock_flt = zblock.reshape((-1,nlevels))\n",
    "    rhoblock_flt = rhoblock.reshape((-1,nlevels))\n",
    "    latblock_flt = latblock.ravel()\n",
    "    results_u = np.array([\n",
    "        ad99_u.momentum_flux_neg_ptv(u,N,z,rho,lat) for u,N,z,rho,lat in zip(ublock_flt,Nblock_flt,zblock_flt,rhoblock_flt,latblock_flt)\n",
    "    ])\n",
    "    results_v = np.array([\n",
    "        ad99_v.momentum_flux_neg_ptv(v,N,z,rho,lat) for v,N,z,rho,lat in zip(vblock_flt,Nblock_flt,zblock_flt,rhoblock_flt,latblock_flt)\n",
    "    ])\n",
    "    \n",
    "    result_u_shp = results_u.reshape((*batch_shape,2,nlevels))\n",
    "    result_u_shp = np.moveaxis(result_u_shp,-2,0)\n",
    "\n",
    "    result_v_shp = results_v.reshape((*batch_shape,2,nlevels))\n",
    "    result_v_shp = np.moveaxis(result_v_shp,-2,0)\n",
    "\n",
    "    result_rtn = np.concatenate([result_u_shp,result_v_shp],axis=0)\n",
    "    return result_rtn \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5338c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = da.map_blocks(\n",
    "    dask_ad99_map_block,\n",
    "    us,\n",
    "    vs\n",
    "    Ns,\n",
    "    height,\n",
    "    rho,\n",
    "    lat_4d,\n",
    "    seeds,\n",
    "    new_axis=[0],\n",
    "    dtype=us.dtype,\n",
    "    chunks= (4,) + tuple(c[0] for c in us.chunks) ).persist()\n",
    "\n",
    "ntv_u_flux = results[0]\n",
    "ptv_u_flux = results[1]\n",
    "ntv_v_flux = results[2]\n",
    "ptv_v_flux = results[3]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad99py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
